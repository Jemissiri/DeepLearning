{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02972eec",
   "metadata": {},
   "source": [
    "# Lab 2: Backpropagation for NXOR\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc026d4f-4cfb-4f95-b255-17baacfe44e9",
   "metadata": {},
   "source": [
    "Grupo 3 \\\n",
    "Alexandre Rodrigues: 75545 \\\n",
    "Tiago Granja: 79845 \\\n",
    "Diogo Silva: 79828"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda23db",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38082d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45194f73-3ae3-474b-84b3-f04a621896c4",
   "metadata": {},
   "source": [
    "---\n",
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d2ed7-4e3c-4aae-b945-a5a110c39f93",
   "metadata": {},
   "source": [
    "To calculate the weights update we first need to feedforward our network. With our 2:1 architecture we have 6 weights, 4 in the hidden layer, $w_{11}^{[1]}, w_{21}^{[1]}, w_{12}^{[1]}, w_{22}^{[1]}$, and 2 in the output layer, $w_1^{[2]}, w_2^{[2]}$, and 3 biases, $b_1^{[1]}, b_2^{[1]}$, in the first layer and $b_1^{[2]}$ in the second. With this we can write our inner weighted sums and outputs as follows:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "z_1^{[1]} = x_1 w_{11}^{[1]} + x_2 w_{21}^{[1]} + b_1^{[1]} \\\\\n",
    "y_1^{[1]} = S(z_1^{[1]}) \\\\\n",
    "\\\\\n",
    "z_2^{[1]} = x_1 w_{12}^{[1]} + x_2 w_{22}^{[1]} + b_2^{[1]} \\\\\n",
    "y_2^{[1]} = S(z_2^{[1]}) \\\\\n",
    "\\\\\n",
    "z_1^{[2]} = y_1^{[1]} w_1^{[2]} + y_2^{[1]} w_2^{[2]} + b_1^{[2]} \\\\\n",
    "y = S(z_1^{[2]})\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Where S is the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b493d-3d17-4227-a120-1ebda704d3fd",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba268ba6-53b7-48a7-ae4c-6651f90942ac",
   "metadata": {},
   "source": [
    "For backpropagation we use the squared error as our error where $E = \\frac{1}{2}(y - t)^2$, where $t$ is our target output. With this we can start writing the expressions for the weight updates such that:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "w_{ij}^{[k]} = w_{ij}^{[k]} - \\upeta \\frac{\\partial E}{\\partial w_{ij}^{[k]}}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d69f74-e028-4b23-8492-b14bebf1ec0e",
   "metadata": {},
   "source": [
    "##### Outer layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d934c-27d5-4789-a6b4-3f26f4c2a9b4",
   "metadata": {},
   "source": [
    "For the outer layer we can write:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20806c67-3dac-4b54-a37e-e6722db0cd64",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "\\Delta w_{i}^{[2]} = \\frac{\\partial E}{\\partial w_{i}^{[2]}} \\\\\n",
    "\\Delta w_{i}^{[2]} = \\frac{\\partial E}{\\partial y}\\frac{\\partial y}{\\partial z_1^{[2]}}\\frac{\\partial z_1^{[2]}}{\\partial w_i^{[2]}} \\\\\n",
    "\\Delta w_{i}^{[2]} = (y - t) S'(z_1^{[2]})y_i^{[1]} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Where the last term is equal to one when taking the partial derivative in order to $b_1^{[2]}$ and $S'$ is the derivative of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c6d2d-0c44-48b3-b2d4-ee64b61b09d1",
   "metadata": {},
   "source": [
    "##### Inner (Hidden) layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0043363-39f7-4ca0-b1e7-df5adfdd88bb",
   "metadata": {},
   "source": [
    "For the inner layer we can write:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e12933-1245-49c6-aa9b-eeb505d16f13",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "\\Delta w_{ij}^{[1]} = \\frac{\\partial E}{\\partial w_{ij}^{[1]}} \\\\\n",
    "\\Delta w_{ij}^{[1]} = \\frac{\\partial E}{\\partial y_j^{[1]}}\\frac{\\partial y_j^{[1]}}{\\partial z_j^{[1]}}\\frac{\\partial z_j^{[1]}}{\\partial w_{ij}^{[1]}} \\\\\n",
    "\\Delta w_{ij}^{[1]} = \\frac{\\partial E}{\\partial y_j^{[1]}} S'(z_j^{[1]}) x_i\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial E}{\\partial y_j^{[1]}} = \\frac{\\partial E}{\\partial y}\\frac{\\partial y}{\\partial z_1^{[2]}}\\frac{\\partial z_1^{[2]}}{\\partial y_j^{[1]}} \\\\\n",
    "\\frac{\\partial E}{\\partial y_j^{[1]}} = (y - t) S'(z_1^{[2]}) w_j^{[2]}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Concluding:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\Delta w_{ij}^{[1]} = (y - t) S'(z_1^{[2]}) w_j^{[2]} S'(z_j^{[1]}) x_i\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Where the last term is equal to one when taking the partial derivative in order to $b_1^2$ and $S'$ is the derivative of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68698b-c638-43bc-ab4c-ab850231abe3",
   "metadata": {},
   "source": [
    "---\n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f406f735-ec2a-435c-94a9-7b2806ed3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: float) -> float:\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x: float) -> float:\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d488834-ef5f-43df-af0a-4f40ffa542b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTwoOneNetwork:\n",
    "\n",
    "    def __init__(self, learning_rate: float):\n",
    "        self._learning_rate = learning_rate\n",
    "        \n",
    "        self._inner_weights = np.random.uniform(0.0, 0.1, (2, 2))\n",
    "        self._inner_biases = np.random.uniform(0.0, 0.1, 2)\n",
    "        self._outer_weights = np.random.uniform(0.0, 0.1, 2)\n",
    "        self._outer_bias = np.random.uniform(0.0, 0.1)\n",
    "\n",
    "        self._inner_sums = np.empty(2)\n",
    "        self._inner_outputs = np.empty(2)\n",
    "    \n",
    "    def _feed_forward(self, x1: float, x2:float) -> float:\n",
    "\n",
    "        # Inner layer\n",
    "        self._inner_sums[0] = self._inner_weights[0][0] * x1 + self._inner_weights[1][0] * x2 + self._inner_biases[0]\n",
    "        self._inner_outputs[0] = sigmoid(self._inner_sums[0])\n",
    "        self._inner_sums[1] = self._inner_weights[0][1] * x1 + self._inner_weights[1][1] * x2 + self._inner_biases[1]\n",
    "        self._inner_outputs[1] = sigmoid(self._inner_sums[1])\n",
    "\n",
    "        # Outer layer\n",
    "        self._outer_sum = self._outer_weights[0] * self._inner_outputs[0] + self._outer_weights[1] * self._inner_outputs[1] + self._outer_bias\n",
    "        self._output = sigmoid(self._outer_sum)\n",
    "\n",
    "        return self._output\n",
    "\n",
    "    def _backpropagate(self, x1: float, x2:float, target: float) -> None:\n",
    "        error = (self._output - target)\n",
    "        delta_output = error * sigmoid_derivative(self._outer_sum)\n",
    "        \n",
    "        # Inner layer\n",
    "        for j in range(2):\n",
    "            self._inner_weights[0][j] -= self._learning_rate * delta_output * self._outer_weights[j] * sigmoid_derivative(self._inner_sums[j]) * x1\n",
    "            self._inner_weights[1][j] -= self._learning_rate * delta_output * self._outer_weights[j] * sigmoid_derivative(self._inner_sums[j]) * x2\n",
    "            self._inner_biases[j] -= self._learning_rate * delta_output * self._outer_weights[j] * sigmoid_derivative(self._inner_sums[j])\n",
    "\n",
    "        # Outer layer\n",
    "        for i in range(2):\n",
    "            self._outer_weights[i] -= self._learning_rate * delta_output * self._inner_outputs[i]\n",
    "        self._outer_bias -= self._learning_rate * delta_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b91364b5-8538-4ee5-80f7-fad925feedd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49994585414077714\n",
      "0.500083575348709\n",
      "0.4999759092988594\n",
      "0.50011359519794\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "\n",
    "target = np.array([[1],\n",
    "                     [0],\n",
    "                     [0],\n",
    "                     [1]])\n",
    "\n",
    "network = BinaryTwoOneNetwork(0.1)\n",
    "iterations = 1000\n",
    "for i in range(iterations):\n",
    "    for j in range(4):\n",
    "        network._feed_forward(x[j][0], x[j][1])\n",
    "        network._backpropagate(x[j][0], x[j][1], target[j][0])\n",
    "\n",
    "for j in range(4):\n",
    "    print(network._feed_forward(x[j][0], x[j][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530c363-55dd-4549-8dfe-5080bf178487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a4401-152c-4e99-89fe-d2a5f0b6d154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
